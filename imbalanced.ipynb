{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in each class:\n",
      "Class 0:  9700\n",
      "Class 1:  300\n"
     ]
    }
   ],
   "source": [
    "# Create imbalanced dataset\n",
    "X, y = make_classification(n_samples=10000, n_classes=2, class_sep=2,\n",
    "                            weights=[0.97, 0.03], n_informative=3, n_redundant=1, flip_y=0,\n",
    "                            n_features=20, random_state=42)\n",
    "\n",
    "# Printing the number of samples in each class\n",
    "print(\"Number of samples in each class:\")\n",
    "print(\"Class 0: \", len(y[y==0]))\n",
    "print(\"Class 1: \", len(y[y==1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into training and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom loss function\n",
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    # Convert y_true to float64\n",
    "    y_true = tf.cast(y_true, tf.float64)\n",
    "    y_pred = tf.cast(y_pred, tf.float64)\n",
    "    \n",
    "    # Calculate class weights\n",
    "    n_samples = len(y_true)\n",
    "    n_positives = tf.reduce_sum(y_true)\n",
    "\n",
    "\n",
    "    n_negatives = tf.cast(n_samples, tf.int32) - tf.cast(n_positives, tf.int32)\n",
    "    alpha = n_negatives / n_samples\n",
    "    beta = 1 - alpha\n",
    "    \n",
    "    # Calculate cross-entropy loss\n",
    "    loss = -(beta * y_true * tf.math.log(y_pred + 1e-7) + alpha * (1 - y_true) * tf.math.log(1 - y_pred + 1e-7))\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define binary classification model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=(20,)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with custom loss function\n",
    "model.compile(optimizer='adam', loss=weighted_binary_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 5s 9ms/step - loss: 0.1078 - val_loss: 0.0234\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0149 - val_loss: 0.0114\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.0084 - val_loss: 0.0086\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0022 - val_loss: 0.0032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19717513940>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "X_train=tf.convert_to_tensor(X_train, dtype=tf.float64)\n",
    "X_test=tf.convert_to_tensor(X_test, dtype=tf.float64)\n",
    "y_train=tf.convert_to_tensor(y_train, dtype=tf.float64)\n",
    "y_test=tf.convert_to_tensor(y_test, dtype=tf.float64)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 3ms/step\n",
      "Accuracy: 0.9935\n",
      "Precision: 1.0\n",
      "Recall: 0.7758620689655172\n",
      "F1 score: 0.8737864077669902\n",
      "AUC-ROC: 0.9964309812138216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = np.round(y_pred)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "f1 = f1_score(y_test, y_pred_binary)\n",
    "auc_roc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 score:\", f1)\n",
    "print(\"AUC-ROC:\", auc_roc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customlossenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "211902647e181cfa32e45f869a905b5f2c6411b62faec8ddd99a070cd3ea7578"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
